{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466266c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8a02ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NUM = 3\n",
    "BATCH_SIZE = 16\n",
    "EPOCH_STEPS = int(5318/BATCH_SIZE)\n",
    "IMAGE_SHAPE = (224, 224, 3)\n",
    "IMAGE_TRAIN = r'C:\\\\Users\\\\Tri\\\\Desktop\\\\preprocessDataSet\\\\train\\\\'\n",
    "IMAGE_TEST=  r'C:\\\\Users\\\\Tri\\\\Desktop\\\\preprocessDataSet\\\\test\\\\'\n",
    "MODEL_NAME = 'Ygooglenet_stroke2.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92b0116",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    #rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "generator_main = train_datagen.flow_from_directory(\n",
    "    IMAGE_TRAIN,\n",
    "    target_size=(IMAGE_SHAPE[0], IMAGE_SHAPE[1]),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "generator_maint = train_datagen.flow_from_directory(\n",
    "    IMAGE_TEST,\n",
    "    target_size=(IMAGE_SHAPE[0], IMAGE_SHAPE[1]),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff5096a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_generator(generator):\n",
    "    while True: # keras requires all generators to be infinite\n",
    "        data = next(generator)\n",
    "        x = data[0]\n",
    "        y = data[1],data[1],data[1]\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ba24b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = my_generator(generator_main)\n",
    "test_generator=my_generator(generator_maint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d91cebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception(x, filters):\n",
    "    # 1x1\n",
    "    path1 = Conv2D(filters=filters[0], kernel_size=(1,1), strides=1, padding='same', activation='relu')(x)\n",
    "\n",
    "    # 1x1->3x3\n",
    "    path2 = Conv2D(filters=filters[1][0], kernel_size=(1,1), strides=1, padding='same', activation='relu')(x)\n",
    "    path2 = Conv2D(filters=filters[1][1], kernel_size=(3,3), strides=1, padding='same', activation='relu')(path2)\n",
    "    \n",
    "    # 1x1->5x5\n",
    "    path3 = Conv2D(filters=filters[2][0], kernel_size=(1,1), strides=1, padding='same', activation='relu')(x)\n",
    "    path3 = Conv2D(filters=filters[2][1], kernel_size=(5,5), strides=1, padding='same', activation='relu')(path3)\n",
    "\n",
    "    # 3x3->1x1\n",
    "    path4 = MaxPooling2D(pool_size=(3,3), strides=1, padding='same')(x)\n",
    "    path4 = Conv2D(filters=filters[3], kernel_size=(1,1), strides=1, padding='same', activation='relu')(path4)\n",
    "\n",
    "    return Concatenate(axis=-1)([path1,path2,path3,path4])\n",
    "\n",
    "\n",
    "def auxiliary(x, name=None):\n",
    "    layer = AveragePooling2D(pool_size=(5,5), strides=3, padding='valid')(x)\n",
    "    layer = Conv2D(filters=128, kernel_size=(1,1), strides=1, padding='same', activation='relu')(layer)\n",
    "    layer = Flatten()(layer)\n",
    "    layer = Dense(units=256, activation='relu')(layer)\n",
    "    layer = Dropout(0.4)(layer)\n",
    "    layer = Dense(units=CLASS_NUM, activation='softmax', name=name)(layer)\n",
    "    return layer\n",
    "\n",
    "\n",
    "def googlenet():\n",
    "    layer_in = Input(shape=IMAGE_SHAPE)\n",
    "    \n",
    "    # stage-1\n",
    "    layer = Conv2D(filters=64, kernel_size=(7,7), strides=2, padding='same', activation='relu')(layer_in)\n",
    "    layer = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "\n",
    "    # stage-2\n",
    "    layer = Conv2D(filters=64, kernel_size=(1,1), strides=1, padding='same', activation='relu')(layer)\n",
    "    layer = Conv2D(filters=192, kernel_size=(3,3), strides=1, padding='same', activation='relu')(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(layer)\n",
    "\n",
    "    # stage-3\n",
    "    layer = inception(layer, [ 64,  (96,128), (16,32), 32]) #3a\n",
    "    layer = inception(layer, [128, (128,192), (32,96), 64]) #3b\n",
    "    layer = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(layer)\n",
    "    \n",
    "    # stage-4\n",
    "    layer = inception(layer, [192,  (96,208),  (16,48),  64]) #4a\n",
    "    aux1  = auxiliary(layer, name='aux1')\n",
    "    layer = inception(layer, [160, (112,224),  (24,64),  64]) #4b\n",
    "    layer = inception(layer, [128, (128,256),  (24,64),  64]) #4c\n",
    "    layer = inception(layer, [112, (144,288),  (32,64),  64]) #4d\n",
    "    aux2  = auxiliary(layer, name='aux2')\n",
    "    layer = inception(layer, [256, (160,320), (32,128), 128]) #4e\n",
    "    layer = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(layer)\n",
    "    \n",
    "    # stage-5\n",
    "    layer = inception(layer, [256, (160,320), (32,128), 128]) #5a\n",
    "    layer = inception(layer, [384, (192,384), (48,128), 128]) #5b\n",
    "    layer = AveragePooling2D(pool_size=(7,7), strides=1, padding='valid')(layer)\n",
    "    \n",
    "    # stage-6\n",
    "    layer = Flatten()(layer)\n",
    "    layer = Dropout(0.4)(layer)\n",
    "    layer = Dense(units=256, activation='linear')(layer)\n",
    "    main = Dense(units=CLASS_NUM, activation='softmax', name='main')(layer)\n",
    "    \n",
    "    model = Model(inputs=layer_in, outputs=[main, aux1, aux2])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d44ba48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = googlenet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1070c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff565db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = ['Adam', 'SGD', 'Adam','SGD']\n",
    "epochs = [5,5,5,5]\n",
    "history_all = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81bbb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(optimizer)):\n",
    "    print('Using optimizer: ' + optimizer[i] + ', Epoch: ' + str(epochs[i]))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  loss_weights={'main': 1.0, 'aux1': 0.3, 'aux2': 0.3},\n",
    "                  optimizer=optimizer[i], metrics=['accuracy'])\n",
    "    \n",
    "    train_history = model.fit(\n",
    "            train_generator,\n",
    "            steps_per_epoch=EPOCH_STEPS,\n",
    "            epochs=epochs[i],\n",
    "            shuffle=True\n",
    "            )\n",
    "    if len(history_all) == 0:\n",
    "            history_all = {key: [] for key in train_history.history}\n",
    "    \n",
    "    for key in history_all:\n",
    "            history_all[key].extend(train_history.history[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585d57ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01443b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_train_history(history, xlabel, ylabel, train):\n",
    "    for item in train:\n",
    "        plt.plot(history[item])\n",
    "    plt.title('Train History')\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend(train, loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "show_train_history(history_all, 'Epoch', 'Accuracy', ('main_accuracy', 'aux1_accuracy', 'aux2_accuracy'))\n",
    "show_train_history(history_all, 'Epoch', 'Loss', ('main_loss', 'aux1_loss', 'aux2_loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194ffc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf347b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "classifier=load_model('Ygooglenet_stroke2.h15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ef93ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "path='C:\\\\Users\\\\Tri\\\\Desktop\\\\preprocessDataSet\\\\'\n",
    "test_data_dir=path+'test\\\\'\n",
    "test_datagen=ImageDataGenerator()\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(224,224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6057eb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator.reset()\n",
    "\n",
    "pred = model.predict_generator(test_generator, steps = len(test_generator), verbose = 1)\n",
    "\n",
    "predicted_class_indices = np.argmax(pred, axis = 1)\n",
    "print(predicted_class_indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
